import os
import time
import re
import asyncio
import aiohttp
import feedparser
import requests
import numpy as np
import pandas as pd
import yfinance as yf
import pandas_datareader.data as web
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from ta.trend import IchimokuIndicator, SMAIndicator
from ta.momentum import RSIIndicator
from transformers import BertTokenizer, BertForSequenceClassification, pipeline

# ======================================================
# â–¼â–¼â–¼ ì‚¬ìš©ì ì„¤ì • ì •ë³´ â–¼â–¼â–¼
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
TELEGRAM_CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')

TARGET_STOCKS = {
    'GOOGL': 'Google Alphabet',
    'MSFT': 'Microsoft',
    'TSLA': 'Tesla',
    'NVDA': 'Nvidia',
    'AMD': 'AMD',
    'PLTR': 'Palantir',
    'AAPL': 'Apple'
}

# ìµœì í™” íŒŒë¼ë¯¸í„°
STOCK_PARAMS = {
    'GOOGL': {'crash': 40, 'rel': 20, 'tech': 20, 'sell': 60},
    'MSFT':  {'crash': 30, 'rel': 10, 'tech': 20, 'sell': 60},
    'TSLA':  {'crash': 40, 'rel': 10, 'tech': 20, 'sell': 60},
    'NVDA':  {'crash': 40, 'rel': 10, 'tech': 20, 'sell': 60},
    'AMD':   {'crash': 30, 'rel': 20, 'tech': 10, 'sell': 60},
    'PLTR':  {'crash': 40, 'rel': 15, 'tech': 20, 'sell': 60},
    'AAPL':  {'crash': 20, 'rel': 20, 'tech': 20, 'sell': 60}
}

W_TREND_MACRO = 30
W_VOL_MACRO = 15
W_MACRO_MACRO = 10
TH_SELL = 80
TH_BUY = 40
# ======================================================

class DangerAlertBot:
    def __init__(self):
        print("ğŸ¤– AI í€€íŠ¸ ì‹œìŠ¤í…œ(News Summary Ver.) ê°€ë™ ì¤‘...")
        try:
            self.tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')
            self.model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')
            self.nlp = pipeline("sentiment-analysis", model=self.model, tokenizer=self.tokenizer)
        except Exception as e:
            print(f"âš ï¸ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.nlp = None
        
        self.macro_keywords = [
            'Federal Reserve', 'The Fed', 'Jerome Powell', 'FOMC', 
            'CPI Inflation', 'Recession', 'Stagflation', 'US Economy',
            'Geopolitical tension', 'Market Crash', 'Liquidity crisis'
        ]

    def send_telegram(self, message):
        if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
            print("âŒ í…”ë ˆê·¸ë¨ í† í° ì—†ìŒ")
            return
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        data = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown", "disable_web_page_preview": True}
        try: requests.post(url, data=data, timeout=10)
        except Exception as e: print(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")

    # ------------------------------------------------------------------
    # [ë‰´ìŠ¤ ë¶„ì„ ì—”ì§„] ìš”ì•½ ê¸°ëŠ¥ ì¶”ê°€
    # ------------------------------------------------------------------
    async def fetch_feed(self, session, keyword):
        url = f"https://news.google.com/rss/search?q={keyword}&hl=en-US&gl=US&ceid=US:en"
        try:
            async with session.get(url, timeout=5) as response:
                if response.status == 200:
                    xml_data = await response.text()
                    return keyword, xml_data
        except: pass
        return keyword, None

    async def process_news_async(self, keywords):
        if not self.nlp: return 0, "", "", "", ""
        
        search_list = [keywords] if isinstance(keywords, str) else keywords
        total_score = 0
        count = 0
        # worst_info êµ¬ì¡°ì— summary ì¶”ê°€
        worst_info = {"score": 1.0, "title": "", "link": "", "source": "", "summary": ""}

        async with aiohttp.ClientSession() as session:
            tasks = [self.fetch_feed(session, key) for key in search_list]
            feeds = await asyncio.gather(*tasks)

            for key, xml_data in feeds:
                if not xml_data: continue
                feed = feedparser.parse(xml_data)
                
                for entry in feed.entries[:3]:
                    try:
                        title = entry.title
                        link = entry.link
                        source = entry.source.title if 'source' in entry else "News"
                        
                        # [ì¶”ê°€] ìš”ì•½ë¬¸ ì¶”ì¶œ ë° HTML íƒœê·¸ ì œê±°
                        raw_summary = entry.get('summary', '') or entry.get('description', '')
                        clean_summary = BeautifulSoup(raw_summary, "html.parser").get_text()
                        # ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸° (ê°€ë…ì„±)
                        if len(clean_summary) > 150:
                            clean_summary = clean_summary[:150] + "..."

                        clean_title = BeautifulSoup(title, "html.parser").get_text()
                        res = self.nlp(clean_title[:512])[0]
                        
                        score = 0
                        if res['label'] == 'positive': score = res['score']
                        elif res['label'] == 'negative': score = -res['score']
                        
                        total_score += score
                        count += 1
                        
                        if score < worst_info["score"] and score < -0.5:
                            worst_info = {
                                "score": score,
                                "title": clean_title,
                                "link": link,
                                "source": source,
                                "summary": clean_summary # ìš”ì•½ ì €ì¥
                            }
                    except: continue
        
        avg_score = total_score / count if count > 0 else 0
        # ë¦¬í„´ê°’ì— summary ì¶”ê°€
        return avg_score, worst_info["title"], worst_info["link"], worst_info["source"], worst_info["summary"]

    def get_news_sentiment(self, target_keywords):
        try:
            return asyncio.run(self.process_news_async(target_keywords))
        except Exception as e:
            print(f"ë‰´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return 0, "", "", "", ""

    # ------------------------------------------------------------------
    # [ë°ì´í„° ìˆ˜ì§‘]
    # ------------------------------------------------------------------
    def get_realtime_price(self, ticker):
        try:
            stock = yf.Ticker(ticker)
            return stock.fast_info.get('last_price', None)
        except: return None

    def get_market_data(self):
        try:
            macro_tickers = ['NQ=F', 'QQQ', '^VIX', '^VIX3M', 'DX-Y.NYB', 'SOXX', 'HYG', '^TNX', '^IRX', 'BTC-USD']
            all_tickers = macro_tickers + list(TARGET_STOCKS.keys())
            
            data = yf.download(all_tickers, period='1mo', interval='1h', prepost=True, progress=False, ignore_tz=True)
            
            if isinstance(data.columns, pd.MultiIndex):
                dfs = {}
                df_macro = pd.DataFrame()
                
                if 'Close' in data.columns:
                    close_data = data['Close']
                    if 'NQ=F' not in close_data.columns: return {}
                    
                    df_macro['Close'] = close_data['NQ=F']
                    df_macro['High'] = data['High']['NQ=F'] if 'High' in data.columns else close_data['NQ=F']
                    df_macro['Low'] = data['Low']['NQ=F'] if 'Low' in data.columns else close_data['NQ=F']
                    df_macro['Volume'] = data['Volume']['QQQ'] if 'Volume' in data.columns and 'QQQ' in data['Volume'].columns else 0
                    
                    ticker_map = {
                        '^VIX': 'VIX', '^VIX3M': 'VIX3M', 'DX-Y.NYB': 'DXY', 
                        'SOXX': 'SOXX', 'HYG': 'HYG', '^TNX': 'TNX', '^IRX': 'IRX', 'BTC-USD': 'BTC'
                    }
                    for t, col in ticker_map.items():
                        if t in close_data.columns:
                            df_macro[col] = close_data[t]
                    
                    df_macro = df_macro.ffill().bfill()
                    dfs['MACRO'] = df_macro
                    
                    for ticker in TARGET_STOCKS.keys():
                        if ticker in close_data.columns:
                            df_stock = pd.DataFrame()
                            df_stock['Close'] = close_data[ticker]
                            df_stock['High'] = data['High'][ticker]
                            df_stock['Low'] = data['Low'][ticker]
                            df_stock['Volume'] = data['Volume'][ticker] if 'Volume' in data.columns else 0
                            dfs[ticker] = df_stock.dropna()
                    return dfs
            return {}
        except Exception as e:
            print(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def get_fundamental_data(self):
        try:
            start_date = datetime.now() - timedelta(days=700)
            unrate = web.DataReader('UNRATE', 'fred', start_date)
            unrate['MA3'] = unrate['UNRATE'].rolling(window=3).mean()
            curr_ma3 = unrate['MA3'].iloc[-1]
            low_12m = unrate['UNRATE'].iloc[-14:-1].min()
            sahm_score = curr_ma3 - low_12m
            return {"unrate": unrate['UNRATE'].iloc[-1], "sahm_score": sahm_score, "is_recession": sahm_score >= 0.50}
        except: return None

    # ------------------------------------------------------------------
    # [ë¶„ì„ ì—”ì§„]
    # ------------------------------------------------------------------
    def analyze_individual(self, ticker, df_stock, df_macro):
        if df_stock.empty or len(df_stock) < 30: return None

        params = STOCK_PARAMS.get(ticker, {'crash': 30, 'rel': 15, 'tech': 15, 'sell': 60})
        
        current_price = df_stock['Close'].iloc[-1]
        prev_close = df_stock['Close'].iloc[-8] 
        daily_pct = (current_price - prev_close) / prev_close * 100

        ichimoku = IchimokuIndicator(high=df_stock['High'], low=df_stock['Low'], window1=9, window2=26, window3=52)
        cloud_bottom = min(ichimoku.ichimoku_a().iloc[-26], ichimoku.ichimoku_b().iloc[-26])
        
        ma20 = SMAIndicator(close=df_stock['Close'], window=20).sma_indicator().iloc[-1]
        ma50 = SMAIndicator(close=df_stock['Close'], window=50).sma_indicator().iloc[-1]
        
        rsi = RSIIndicator(close=df_stock['Close'], window=14).rsi().iloc[-1]
        vol_ma = df_stock['Volume'].rolling(window=20).mean().iloc[-1]
        vol_ratio = df_stock['Volume'].iloc[-1] / vol_ma if vol_ma > 0 else 0

        nq_chg = (df_macro['Close'].iloc[-1] - df_macro['Close'].iloc[-8]) / df_macro['Close'].iloc[-8] * 100
        rel_strength = daily_pct - nq_chg

        # ë‰´ìŠ¤ ë¶„ì„ (ìš”ì•½ í¬í•¨ ë°˜í™˜ê°’ ë°›ê¸°)
        news_score, worst_n, worst_l, worst_s, worst_sum = self.get_news_sentiment(ticker)

        score = 0
        reasons = []

        if daily_pct < -3.0: score += params['crash']; reasons.append(f"ğŸ“‰ í­ë½ ({daily_pct:.1f}%)")
        if rel_strength < -1.5: score += params['rel']; reasons.append("ìƒëŒ€ì  ì•½ì„¸")
        
        tech_bad = []
        if current_price < cloud_bottom: tech_bad.append("êµ¬ë¦„ëŒ€ ì´íƒˆ")
        if ma20 < ma50 and current_price < ma20: tech_bad.append("ë°ë“œí¬ë¡œìŠ¤")
        if rsi < 30: tech_bad.append("ê³¼ë§¤ë„")
        if vol_ratio > 2.0 and daily_pct < 0: tech_bad.append("íˆ¬ë§¤ ê±°ë˜ëŸ‰")
        
        if tech_bad:
            score += params['tech']
            reasons.append(f"ê¸°ìˆ ì ({','.join(tech_bad)})")
            
        if news_score < -0.3:
            score += 20
            src = f"[{worst_s}]" if worst_s else ""
            # ìš”ì•½ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶”ê°€
            news_msg = f"ğŸ“° ì•…ì¬: {src} {worst_n[:20]}..."
            if worst_sum:
                news_msg += f"\n    â”” {worst_sum[:60]}..."
            reasons.append(news_msg)

        score = max(0, min(score, 100))
        return {"ticker": ticker, "price": current_price, "change": daily_pct, "score": score, "threshold": params['sell'], "reasons": reasons}

    def analyze_danger(self):
        dfs = self.get_market_data()
        if not dfs or 'MACRO' not in dfs: 
            print("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return
        df = dfs['MACRO']
        
        now = datetime.now() + timedelta(hours=9)
        
        curr_close = df['Close'].iloc[-1]
        idx_day = -24 if len(df) >= 24 else 0
        daily_chg = (curr_close - df['Close'].iloc[idx_day]) / df['Close'].iloc[idx_day] * 100
        
        vix = df['VIX'].iloc[-1]
        vix3m = df['VIX3M'].iloc[-1] if 'VIX3M' in df.columns else vix * 1.1
        is_backwardation = vix > (vix3m * 1.02)
        vix_ratio = vix / vix3m
        
        # ë‰´ìŠ¤ ë¶„ì„ (ìš”ì•½ í¬í•¨)
        news_score, w_title, w_link, w_src, w_sum = self.get_news_sentiment(self.macro_keywords)
        
        danger_score = 0
        reasons = []
        
        if daily_chg < -1.5: danger_score += W_TREND_MACRO; reasons.append(f"ğŸ“‰ ì§€ìˆ˜ ê¸‰ë½ ({daily_chg:.2f}%)")
        
        if is_backwardation:
            danger_score += 25
            reasons.append(f"ğŸš¨ VIX ë°±ì›Œë°ì´ì…˜ (ê³µí¬í™•ì‚° {vix_ratio:.2f}ë°°)")
        elif vix > 30:
            danger_score += 15
            reasons.append(f"ğŸ˜± ê³µí¬ì§€ìˆ˜ ìœ„í—˜ê¶Œ ({vix:.1f})")
            
        dxy_chg = (df['DXY'].iloc[-1] - df['DXY'].iloc[idx_day]) / df['DXY'].iloc[idx_day] * 100
        if dxy_chg > 0.3: danger_score += W_MACRO_MACRO; reasons.append("ğŸ’µ ë‹¬ëŸ¬ ê¸‰ë“±")
        
        tnx = df['TNX'].iloc[-1]
        irx = df['IRX'].iloc[-1]
        spread = tnx - irx
        if spread < -0.5: danger_score += 10; reasons.append("âš ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ ì—­ì „ ì‹¬í™”")
        
        if news_score < -0.25: 
            danger_score += W_VOL_MACRO
            reasons.append(f"ğŸ“° ë‰´ìŠ¤ ì‹¬ë¦¬ ì•…í™” ({news_score:.2f})")
            
        ma20 = df['Close'].rolling(20).mean().iloc[-1]
        ma50 = df['Close'].rolling(50).mean().iloc[-1]
        if ma20 < ma50 and curr_close < ma20:
            danger_score += 15
            reasons.append("ğŸ“‰ ì™„ì „ ì—­ë°°ì—´ ì§„ì…")

        fund = self.get_fundamental_data()
        if fund and fund['is_recession']:
            danger_score += 30
            reasons.append(f"ğŸ›‘ ê²½ê¸° ì¹¨ì²´ ì‹ í˜¸ (ìƒ´ì˜ ë²•ì¹™)")

        danger_score = max(0, min(danger_score, 100))
        
        status = "ğŸŸ¢ ì•ˆì •"
        if danger_score >= TH_SELL: status = "ğŸ”´ ìœ„í—˜ (í˜„ê¸ˆí™” ê¶Œì¥)"
        elif danger_score >= TH_BUY: status = "ğŸŸ¡ ì£¼ì˜ (ê´€ë§)"
        
        stock_results = []
        for t in TARGET_STOCKS:
            if t in dfs:
                res = self.analyze_individual(t, dfs[t], df)
                if res: stock_results.append(res)
        stock_results.sort(key=lambda x: x['score'], reverse=True)

        msg = f"ğŸ”” *AI ë§ˆì¼“ ì›Œì¹˜ (News Summary)*\nğŸ“… {now.strftime('%Y-%m-%d %H:%M')} (KST)\nğŸš¦ ì‹œì¥ìƒíƒœ: {status} ({danger_score}ì )\n\n"
        
        msg += "*1ï¸âƒ£ í•µì‹¬ ìœ„í—˜ ìš”ì¸*\n"
        if reasons: msg += "\n".join(["â–ª " + r for r in reasons])
        else: msg += "â–ª íŠ¹ì´ì‚¬í•­ ì—†ìŒ (ì–‘í˜¸)"
        
        msg += f"\n\n*2ï¸âƒ£ ë§¤í¬ë¡œ ëŒ€ì‹œë³´ë“œ*\nâ€¢ ë‚˜ìŠ¤ë‹¥: {curr_close:,.0f} ({daily_chg:+.2f}%)\nâ€¢ VIXêµ¬ì¡°: {'âš ï¸ ì—­ì „' if is_backwardation else 'âœ… ì •ìƒ'} ({vix:.1f}/{vix3m:.1f})\nâ€¢ ë‹¬ëŸ¬: {df['DXY'].iloc[-1]:.2f}\nâ€¢ ê¸ˆë¦¬ì°¨: {spread:.2f}p\n"
        
        if fund: msg += f"â€¢ ì‹¤ì—…ë¥ : {fund['unrate']}%\n"
        
        if w_title:
            cl_title = re.sub(r'[\[\]\*\_]', '', w_title)[:25] + "..."
            src_tag = f"[{w_src}]" if w_src else "[News]"
            msg += f"\n*3ï¸âƒ£ ì£¼ìš” ë‰´ìŠ¤ ì‹¬ë¦¬*\nâ€¢ ì ìˆ˜: {news_score:.2f}\nâ€¢ ì´ìŠˆ: {src_tag} [{cl_title}]({w_link})\n"
            # [ì¶”ê°€] ë‰´ìŠ¤ ìš”ì•½ ì¶œë ¥
            if w_sum:
                msg += f"  â”” ğŸ“ ìš”ì•½: {w_sum}\n"
            
        msg += "\n*ğŸ“Š ê´€ì‹¬ ì¢…ëª© ìœ„í—˜ë„*\n"
        for s in stock_results:
            icon = "ğŸ”´" if s['score'] >= s['threshold'] else "ğŸŸ¡" if s['score'] >= 40 else "ğŸŸ¢"
            msg += f"{icon} {s['ticker']}: {s['score']}ì  ({s['change']:+.1f}%)\n"
            if s['reasons']: msg += f"  â”” {', '.join(s['reasons'])}\n"

        self.send_telegram(msg)

if __name__ == "__main__":
    bot = DangerAlertBot()
    bot.analyze_danger()
