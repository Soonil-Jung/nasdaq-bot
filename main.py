import os
import time
import re
import asyncio
import aiohttp
import feedparser
import requests
import numpy as np
import pandas as pd
import yfinance as yf
import pandas_datareader.data as web
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from ta.trend import IchimokuIndicator, SMAIndicator
from ta.momentum import RSIIndicator
from transformers import BertTokenizer, BertForSequenceClassification, pipeline

# ======================================================
# â–¼â–¼â–¼ [STRATEGY UPGRADE] í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹± â–¼â–¼â–¼
# ì„¤ëª…: ê¸°ì¡´ Tech ì¼ë³€ë„ì—ì„œ 'AI ì „ë ¥/ì¸í”„ë¼' í•µì‹¬ ì¢…ëª© í¸ì…
# ======================================================
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
TELEGRAM_CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')

TARGET_STOCKS = {
    # [Tech Core]
    'GOOGL': 'Google Alphabet',
    'MSFT': 'Microsoft',
    'NVDA': 'Nvidia',
    'PLTR': 'Palantir',
    # [AI Power & Infra - The New Alpha]
    'NEE': 'NextEra Energy',   # ì¬ìƒì—ë„ˆì§€ ëŒ€ì¥
    'CEG': 'Constellation En', # ì›ìë ¥ ëŒ€ì¥
    'ETN': 'Eaton Corp',       # ì „ë ¥ë§/ë³€ì••ê¸°
    'XLU': 'Utilities ETF'     # ìœ í‹¸ë¦¬í‹° ì„¹í„° ì§€í‘œ
}

# ì¢…ëª©ë³„ ë¯¼ê°ë„ ì„¤ì • (ìœ í‹¸ë¦¬í‹°ëŠ” Techë³´ë‹¤ ë³€ë™ì„± í—ˆìš©í­ì„ ì¢ê²Œ ì„¤ì •)
STOCK_PARAMS = {
    'GOOGL': {'crash': 40, 'rel': 20, 'tech': 20, 'sell': 60},
    'MSFT':  {'crash': 30, 'rel': 10, 'tech': 20, 'sell': 60},
    'NVDA':  {'crash': 40, 'rel': 10, 'tech': 20, 'sell': 60},
    'PLTR':  {'crash': 40, 'rel': 15, 'tech': 20, 'sell': 60},
    # [Defensive Growth] ë°©ì–´ì£¼ ì„±ê²©ì´ ì„ì¸ ì¢…ëª©ë“¤
    'NEE':   {'crash': 25, 'rel': 15, 'tech': 20, 'sell': 55},
    'CEG':   {'crash': 30, 'rel': 20, 'tech': 20, 'sell': 60},
    'ETN':   {'crash': 30, 'rel': 20, 'tech': 20, 'sell': 60},
    'XLU':   {'crash': 20, 'rel': 10, 'tech': 10, 'sell': 50}
}

W_TREND_MACRO = 35 
W_VOL_MACRO = 20
W_MACRO_MACRO = 10 
TH_SELL = 60
TH_BUY = 30
# ======================================================

class MarketStrategyBot:
    def __init__(self):
        print("ğŸ›ï¸ [Wall St. Strategist Bot v3.0] ê°€ë™ ì¤‘... (Sector Rotation Mode)")
        try:
            self.tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')
            self.model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')
            self.nlp = pipeline("sentiment-analysis", model=self.model, tokenizer=self.tokenizer)
        except Exception as e:
            print(f"âš ï¸ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.nlp = None
        
        # í‚¤ì›Œë“œ í™•ì¥: ì—ë„ˆì§€ ë° ì¸í”„ë¼ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ê°€
        self.macro_keywords = [
            'Federal Reserve', 'Powell', 'US CPI', 'Recession', 
            'AI Bubble', 'Data Center Energy', 'Power Grid Shortage', 'Nuclear Energy'
        ]

    def send_telegram(self, message):
        if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID: return
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        data = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown", "disable_web_page_preview": True}
        try: requests.post(url, data=data, timeout=10)
        except: pass

    async def fetch_feed(self, session, keyword):
        url = f"https://news.google.com/rss/search?q={keyword}&hl=en-US&gl=US&ceid=US:en"
        try:
            async with session.get(url, timeout=5) as response:
                if response.status == 200:
                    return keyword, await response.text()
        except: pass
        return keyword, None

    async def process_news_async(self, keywords):
        if not self.nlp: return 0, "", "", "", ""
        search_list = [keywords] if isinstance(keywords, str) else keywords
        total_score, count = 0, 0
        worst_info = {"score": 1.0, "title": "", "link": "", "source": "", "summary": ""}

        async with aiohttp.ClientSession() as session:
            tasks = [self.fetch_feed(session, key) for key in search_list]
            feeds = await asyncio.gather(*tasks)

            for key, xml_data in feeds:
                if not xml_data: continue
                feed = feedparser.parse(xml_data)
                for entry in feed.entries[:3]:
                    try:
                        title = entry.title
                        link = entry.link
                        source = entry.source.title if 'source' in entry else "News"
                        raw_sum = entry.get('summary', '') or entry.get('description', '')
                        clean_sum = BeautifulSoup(raw_sum, "html.parser").get_text().strip()
                        clean_title = BeautifulSoup(title, "html.parser").get_text()
                        
                        # BERT ëª¨ë¸ ê¸¸ì´ ì œí•œ ì²˜ë¦¬
                        inputs = clean_title[:512]
                        res = self.nlp(inputs)[0]
                        score = res['score'] if res['label'] == 'positive' else -res['score']
                        
                        total_score += score
                        count += 1
                        
                        # ê°€ì¥ ë¶€ì •ì ì¸ ë‰´ìŠ¤ í¬ì°©
                        if score < worst_info["score"]:
                            worst_info = {"score": score, "title": clean_title, "link": link, "source": source, "summary": clean_sum}
                    except: continue
        
        avg_score = total_score / count if count > 0 else 0
        return avg_score, worst_info["title"], worst_info["link"], worst_info["source"], worst_info["summary"]

    def get_news_sentiment(self, target_keywords):
        try: return asyncio.run(self.process_news_async(target_keywords))
        except: return 0, "", "", "", ""

    def get_realtime_price(self, ticker):
        try: return yf.Ticker(ticker).fast_info.get('last_price', None)
        except: return None

    def get_market_data(self):
        try:
            # QQQ(ê¸°ìˆ ì£¼)ì™€ XLU(ìœ í‹¸ë¦¬í‹°)ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œí•˜ì—¬ ë¡œí…Œì´ì…˜ ë¶„ì„ì— ì‚¬ìš©
            macro_tickers = ['NQ=F', 'QQQ', '^VIX', '^VIX3M', 'DX-Y.NYB', 'SOXX', 'HYG', '^TNX', '^IRX', 'BTC-USD']
            all_tickers = macro_tickers + list(TARGET_STOCKS.keys())
            
            # ì¤‘ë³µ ì œê±°
            all_tickers = list(set(all_tickers))
            
            data = yf.download(all_tickers, period='1y', interval='1d', prepost=True, progress=False, ignore_tz=True)
            
            if isinstance(data.columns, pd.MultiIndex) and 'Close' in data.columns:
                dfs = {}
                df_macro = pd.DataFrame()
                close_data = data['Close']
                
                # ë§¤í¬ë¡œ ê¸°ë³¸ ë°ì´í„°
                if 'NQ=F' in close_data.columns:
                    df_macro['Close'] = close_data['NQ=F']
                    df_macro['High'] = data['High']['NQ=F']
                    df_macro['Low'] = data['Low']['NQ=F']
                else:
                    # ì„ ë¬¼ì´ ì—†ìœ¼ë©´ QQQë¡œ ëŒ€ì²´
                    df_macro['Close'] = close_data['QQQ']
                    df_macro['High'] = data['High']['QQQ']
                    df_macro['Low'] = data['Low']['QQQ']

                ticker_map = {'^VIX': 'VIX', '^VIX3M': 'VIX3M', 'DX-Y.NYB': 'DXY', 'SOXX': 'SOXX', 'HYG': 'HYG', '^TNX': 'TNX', '^IRX': 'IRX', 'BTC-USD': 'BTC', 'QQQ': 'QQQ'}
                for t, col in ticker_map.items():
                    if t in close_data.columns: df_macro[col] = close_data[t]
                
                df_macro = df_macro.ffill().bfill()
                dfs['MACRO'] = df_macro
                
                for ticker in TARGET_STOCKS.keys():
                    if ticker in close_data.columns:
                        df_stock = pd.DataFrame()
                        df_stock['Close'] = close_data[ticker]
                        df_stock['High'] = data['High'][ticker]
                        df_stock['Low'] = data['Low'][ticker]
                        dfs[ticker] = df_stock.dropna()
                
                # ìœ í‹¸ë¦¬í‹° ë°ì´í„°ê°€ ê°œë³„ ì¢…ëª©ìœ¼ë¡œ ì—†ì–´ë„ ETF(XLU) ë°ì´í„°ëŠ” dfsì— ì €ì¥
                if 'XLU' in close_data.columns:
                    dfs['XLU_DATA'] = pd.DataFrame({'Close': close_data['XLU']})

                return dfs
            return {}
        except Exception as e:
            print(f"Data Fetch Error: {e}")
            return {}

    def get_fundamental_data(self):
        try:
            start = datetime.now() - timedelta(days=700)
            unrate = web.DataReader('UNRATE', 'fred', start)
            unrate['MA3'] = unrate['UNRATE'].rolling(3).mean()
            score = unrate['MA3'].iloc[-1] - unrate['UNRATE'].iloc[-14:-1].min()
            return {"unrate": unrate['UNRATE'].iloc[-1], "is_recession": score >= 0.50}
        except: return None

    def analyze_individual(self, ticker, df_stock, df_macro):
        if len(df_stock) < 30: return None
        params = STOCK_PARAMS.get(ticker, {'crash': 30, 'rel': 15, 'tech': 15, 'sell': 60})
        
        curr = df_stock['Close'].iloc[-1]
        prev = df_stock['Close'].iloc[-2]
        chg = (curr - prev) / prev * 100

        ichimoku = IchimokuIndicator(high=df_stock['High'], low=df_stock['Low'], window1=9, window2=26, window3=52)
        cloud = min(ichimoku.ichimoku_a().iloc[-26], ichimoku.ichimoku_b().iloc[-26])
        ma20 = SMAIndicator(close=df_stock['Close'], window=20).sma_indicator().iloc[-1]
        ma50 = SMAIndicator(close=df_stock['Close'], window=50).sma_indicator().iloc[-1]
        rsi = RSIIndicator(close=df_stock['Close'], window=14).rsi().iloc[-1]
        
        rel_str = chg - ((df_macro['Close'].iloc[-1] - df_macro['Close'].iloc[-2]) / df_macro['Close'].iloc[-2] * 100)
        news_score, wn, wl, ws, wsum = self.get_news_sentiment(ticker)

        score = 0
        reasons = []
        if chg < -3.0: score += params['crash']; reasons.append(f"ğŸ“‰ í­ë½ ({chg:.1f}%)")
        if rel_str < -1.5: score += params['rel']; reasons.append("ìƒëŒ€ì  ì•½ì„¸")
        
        tech = []
        if curr < cloud: tech.append("êµ¬ë¦„ëŒ€ ì´íƒˆ")
        if ma20 < ma50 and curr < ma20: tech.append("ë°ë“œí¬ë¡œìŠ¤")
        if rsi < 30: tech.append("ê³¼ë§¤ë„")
        if tech: score += params['tech']; reasons.append(f"ê¸°ìˆ ì ({','.join(tech)})")
            
        if news_score < -0.3:
            score += 20
            reasons.append(f"ğŸ“° ì•…ì¬: {wn[:15]}...")

        return {"ticker": ticker, "price": curr, "change": chg, "score": min(score, 100), "threshold": params['sell'], "reasons": reasons}

    def analyze_market_flow(self):
        dfs = self.get_market_data()
        if not dfs or 'MACRO' not in dfs: return
        df = dfs['MACRO']
        
        now = datetime.now() + timedelta(hours=9)
        
        # [ì£¼ë§ ë¸Œë¦¬í•‘ ë¡œì§ ìƒëµ - í‰ì¼ ë¡œì§ ê°•í™”]
        
        curr = df['Close'].iloc[-1]
        prev = df['Close'].iloc[-2]
        chg = (curr - prev) / prev * 100
        
        high_52w = df['Close'].rolling(252).max().iloc[-1]
        drawdown = (curr - high_52w) / high_52w * 100
        
        # ì§€í‘œ ê³„ì‚°
        ma20 = df['Close'].rolling(20).mean().iloc[-1]
        ma50 = df['Close'].rolling(50).mean().iloc[-1]
        ma120 = df['Close'].rolling(120).mean().iloc[-1]
        vix = df['VIX'].iloc[-1]
        vix3m = df['VIX3M'].iloc[-1] if 'VIX3M' in df.columns else vix * 1.1
        
        danger_score = 0
        reasons = []
        
        # ==========================================================
        # 1. [NEW STRATEGY] ì„¹í„° ë¡œí…Œì´ì…˜ (Sector Rotation) ê°ì§€
        # ==========================================================
        try:
            qqq_curr = df['QQQ'].iloc[-1] if 'QQQ' in df.columns else df['Close'].iloc[-1]
            qqq_prev = df['QQQ'].iloc[-2] if 'QQQ' in df.columns else df['Close'].iloc[-2]
            qqq_chg = (qqq_curr - qqq_prev) / qqq_prev * 100

            if 'XLU_DATA' in dfs:
                xlu_curr = dfs['XLU_DATA']['Close'].iloc[-1]
                xlu_prev = dfs['XLU_DATA']['Close'].iloc[-2]
                xlu_chg = (xlu_curr - xlu_prev) / xlu_prev * 100
            else:
                xlu_chg = 0

            # ë¡œí…Œì´ì…˜ ì •ì˜: ê¸°ìˆ ì£¼ í•˜ë½(-0.5% ì´í•˜) & ìœ í‹¸ë¦¬í‹° ìƒìŠ¹(+0.3% ì´ìƒ)
            is_rotation = (qqq_chg < -0.5) and (xlu_chg > 0.3)
            
            # ì‹œìŠ¤í…œ ë¶•ê´´ ì •ì˜: ê¸°ìˆ ì£¼ í­ë½ & ìœ í‹¸ë¦¬í‹° ë™ë°˜ í­ë½ (í”¼ë‚œì²˜ ì—†ìŒ)
            is_system_crash = (qqq_chg < -2.0) and (xlu_chg < -1.0)
            
        except:
            is_rotation = False
            is_system_crash = False
            xlu_chg = 0

        # ==========================================================
        # 2. ìœ„í—˜ ì ìˆ˜ ê³„ì‚° (Scoring Logic)
        # ==========================================================
        
        # A. ê¸°ë³¸ ì¶”ì„¸
        if chg < -1.5: danger_score += W_TREND_MACRO; reasons.append(f"ğŸ“‰ ì§€ìˆ˜ ê¸‰ë½ ({chg:.2f}%)")
        if drawdown < -20: danger_score += 30; reasons.append(f"ğŸ“‰ ë² ì–´ë§ˆì¼“ (MDD {drawdown:.1f}%)")
        
        # B. ê³µí¬ì§€ìˆ˜ (VIX)
        if vix > vix3m * 1.02: danger_score += 35; reasons.append(f"ğŸš¨ VIX ì—­ì „ (ë³€ë™ì„± í­ë°œ)")
        elif vix > 30: danger_score += 20; reasons.append(f"ğŸ˜± ê³µí¬ êµ¬ê°„ ({vix:.1f})")
            
        # C. ë§¤í¬ë¡œ ìœ ë™ì„± (Liquidity)
        dxy_chg = (df['DXY'].iloc[-1] - df['DXY'].iloc[-2]) / df['DXY'].iloc[-2] * 100
        # [ê°•í™”] 0.5 -> 0.4ë¡œ ë¯¼ê°ë„ ìƒí–¥ (í‚¹ë‹¬ëŸ¬ ê²½ê³„)
        if dxy_chg > 0.4: danger_score += 15; reasons.append("ğŸ’µ ë‹¬ëŸ¬ ê¸‰ë“± (ìœ ë™ì„± ì¶•ì†Œ)")
        
        spread = df['TNX'].iloc[-1] - df['IRX'].iloc[-1]
        if spread < -0.5: danger_score += 10; reasons.append("âš ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ ì—­ì „")
        
        # D. ë‰´ìŠ¤ ì‹¬ë¦¬
        news_score, w_title, w_link, w_src, w_sum = self.get_news_sentiment(self.macro_keywords)
        if news_score < -0.3: danger_score += 15; reasons.append(f"ğŸ“° ê±°ì‹œê²½ì œ ì‹¬ë¦¬ ì•…í™”")

        # E. ë¡œí…Œì´ì…˜ ë°˜ì˜ (ì „ëµì  ê°€ê°)
        if is_rotation:
            danger_score -= 15 # ê±´ì „í•œ ì¡°ì •ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ ì ìˆ˜ ì°¨ê°
            reasons.append(f"ğŸ”„ ì„¹í„° ë¡œí…Œì´ì…˜ (Techâ–¼ Powerâ–²)")
        
        if is_system_crash:
            danger_score += 25 # í”¼í•  ê³³ ì—†ëŠ” í•˜ë½
            reasons.append(f"ğŸ†˜ ì‹œìŠ¤í…œ ë¶•ê´´ (Tech & Util ë™ë°˜ íˆ¬ë§¤)")

        # ê²½ê¸°ì¹¨ì²´ ë°ì´í„° í™•ì¸
        fund = self.get_fundamental_data()
        if fund and fund['is_recession']: danger_score += 30; reasons.append("ğŸ›‘ ê²½ê¸° ì¹¨ì²´ ì‹œê·¸ë„")

        danger_score = max(0, min(danger_score, 100))
        
        # ==========================================================
        # 3. ê²°ê³¼ ë¦¬í¬íŒ… (Reporting)
        # ==========================================================
        status = "ğŸŸ¢ ì•ˆì •"
        if danger_score >= TH_SELL: status = "ğŸ”´ ìœ„í—˜ (í˜„ê¸ˆí™•ë³´)"
        elif danger_score >= TH_BUY: status = "ğŸŸ¡ ì£¼ì˜ (ë°©ì–´ì£¼ ì´ë™)"
        
        stock_results = []
        for t in TARGET_STOCKS:
            if t in dfs:
                res = self.analyze_individual(t, dfs[t], df)
                if res: stock_results.append(res)
        stock_results.sort(key=lambda x: x['score'], reverse=True)

        # ì´ëª¨ì§€ ì„¸íŒ…
        trend_st = "ìƒìŠ¹âœ…" if curr > ma120 else "í•˜ë½âš ï¸"
        xlu_emoji = "ğŸ›¡ï¸ê°•ì„¸" if xlu_chg > 0.5 else "ì•½ì„¸"
        
        msg = f"ğŸ›ï¸ *Wall St. Strategist (v3.0)*\n"
        msg += f"ğŸ“… {now.strftime('%Y-%m-%d %H:%M')} (KST)\n"
        msg += f"ğŸš¦ ë§ˆì¼“ êµ­ë©´: {status} ({danger_score}ì )\n\n"
        
        msg += "*1ï¸âƒ£ Market Flow (ìœ ë™ì„±)*\n"
        if reasons: msg += "\n".join(["â–ª " + r for r in reasons])
        else: msg += "â–ª íŠ¹ì´ì‚¬í•­ ì—†ìŒ (Goldilocks)"
        
        msg += f"\n\n*2ï¸âƒ£ Sector Dashboard*\n"
        msg += f"â€¢ Nasdaq(Tech): {curr:,.0f} ({chg:+.2f}%)\n"
        msg += f"â€¢ Utilities(Power): {dfs['XLU_DATA']['Close'].iloc[-1]:.2f} ({xlu_chg:+.2f}%) {xlu_emoji}\n"
        msg += f"â€¢ VIX Term: {'ì •ìƒâœ…' if vix < vix3m else 'ì—­ì „ğŸš¨'}\n"
        msg += f"â€¢ Dollar Index: {df['DXY'].iloc[-1]:.2f} ({dxy_chg:+.2f}%)\n"
        
        if w_title:
            cl_title = re.sub(r'[\[\]\*\_]', '', w_title)[:25] + "..."
            msg += f"\n*3ï¸âƒ£ Smart Money News*\nâ€¢ ì‹¬ë¦¬: {news_score:.2f}\nâ€¢ í—¤ë“œë¼ì¸: [{w_src}] {cl_title}\n"
            
        msg += "\n*ğŸ“Š Alpha Portfolio Watch*\n"
        for s in stock_results:
            icon = "ğŸ”´" if s['score'] >= s['threshold'] else "ğŸŸ¡" if s['score'] >= 40 else "ğŸŸ¢"
            # ì¢…ëª© ì˜†ì— ì„¹í„° íŒíŠ¸ í‘œì‹œ
            sec_hint = "âš¡" if s['ticker'] in ['NEE', 'CEG', 'ETN', 'XLU'] else "ğŸ’»"
            msg += f"{icon} {s['ticker']}{sec_hint}: {s['score']}ì  ({s['change']:+.1f}%)\n"
            if s['reasons']: msg += f"  â”” {', '.join(s['reasons'])}\n"

        self.send_telegram(msg)

if __name__ == "__main__":
    bot = MarketStrategyBot()
    bot.analyze_market_flow()
