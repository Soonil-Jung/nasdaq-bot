import os
import time
import re
import asyncio
import aiohttp
import feedparser
import requests
import numpy as np
import pandas as pd
import yfinance as yf
import pandas_datareader.data as web
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from ta.trend import IchimokuIndicator, SMAIndicator
from ta.momentum import RSIIndicator
from transformers import BertTokenizer, BertForSequenceClassification, pipeline

# ======================================================
# â–¼â–¼â–¼ ì‚¬ìš©ì ì„¤ì • ì •ë³´ â–¼â–¼â–¼
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_TOKEN')
TELEGRAM_CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')

TARGET_STOCKS = {
    'GOOGL': 'Google Alphabet',
    'MSFT': 'Microsoft',
    'TSLA': 'Tesla',
    'NVDA': 'Nvidia',
    'AMD': 'AMD',
    'PLTR': 'Palantir',
    'AAPL': 'Apple'
}

# ìµœì í™” íŒŒë¼ë¯¸í„°
STOCK_PARAMS = {
    'GOOGL': {'crash': 40, 'rel': 20, 'tech': 20, 'sell': 60},
    'MSFT':  {'crash': 30, 'rel': 10, 'tech': 20, 'sell': 60},
    'TSLA':  {'crash': 40, 'rel': 10, 'tech': 20, 'sell': 60},
    'NVDA':  {'crash': 40, 'rel': 10, 'tech': 20, 'sell': 60},
    'AMD':   {'crash': 30, 'rel': 20, 'tech': 10, 'sell': 60},
    'PLTR':  {'crash': 40, 'rel': 15, 'tech': 20, 'sell': 60},
    'AAPL':  {'crash': 20, 'rel': 20, 'tech': 20, 'sell': 60}
}

W_TREND_MACRO = 30
W_VOL_MACRO = 15
W_MACRO_MACRO = 10
TH_SELL = 80
TH_BUY = 40
# ======================================================

class DangerAlertBot:
    def __init__(self):
        print("ğŸ¤– AI í€€íŠ¸ ì‹œìŠ¤í…œ(Pro Ver.) ê°€ë™ ì¤‘...")
        try:
            # FinBERT: ê¸ˆìœµ íŠ¹í™” ê°ì„± ë¶„ì„ ëª¨ë¸
            self.tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')
            self.model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')
            self.nlp = pipeline("sentiment-analysis", model=self.model, tokenizer=self.tokenizer)
        except Exception as e:
            print(f"âš ï¸ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.nlp = None
        
        self.macro_keywords = [
            'Federal Reserve', 'The Fed', 'Jerome Powell', 'FOMC', 
            'CPI Inflation', 'Recession', 'Stagflation', 'US Economy',
            'Geopolitical tension', 'Market Crash', 'Liquidity crisis'
        ]

    def send_telegram(self, message):
        if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:
            print("âŒ í…”ë ˆê·¸ë¨ í† í° ì—†ìŒ")
            return
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        data = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown", "disable_web_page_preview": True}
        try: requests.post(url, data=data, timeout=10)
        except Exception as e: print(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")

    # ------------------------------------------------------------------
    # [ë‰´ìŠ¤ ë¶„ì„ ì—”ì§„] ë¹„ë™ê¸° RSS í”¼ë“œ + FinBERT (ì†ë„/ì‹ ë¢°ì„± ê°œì„ )
    # ------------------------------------------------------------------
    async def fetch_feed(self, session, keyword):
        """êµ¬ê¸€ ë‰´ìŠ¤ RSS ë¹„ë™ê¸° ìš”ì²­"""
        url = f"https://news.google.com/rss/search?q={keyword}&hl=en-US&gl=US&ceid=US:en"
        try:
            async with session.get(url, timeout=5) as response:
                if response.status == 200:
                    xml_data = await response.text()
                    return keyword, xml_data
        except: pass
        return keyword, None

    async def process_news_async(self, keywords):
        """ë‰´ìŠ¤ ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬ ë° AI ê°ì„± ë¶„ì„"""
        if not self.nlp: return 0, "", "", ""
        
        search_list = [keywords] if isinstance(keywords, str) else keywords
        total_score = 0
        count = 0
        worst_info = {"score": 1.0, "title": "", "link": "", "source": ""}

        async with aiohttp.ClientSession() as session:
            tasks = [self.fetch_feed(session, key) for key in search_list]
            feeds = await asyncio.gather(*tasks)

            for key, xml_data in feeds:
                if not xml_data: continue
                feed = feedparser.parse(xml_data)
                
                # í‚¤ì›Œë“œ ë‹¹ ìµœì‹  3ê°œ ê¸°ì‚¬ë§Œ ë¶„ì„ (ì†ë„ ìµœì í™”)
                for entry in feed.entries[:3]:
                    try:
                        title = entry.title
                        link = entry.link
                        source = entry.source.title if 'source' in entry else "News"
                        
                        # HTML íƒœê·¸ ì œê±°
                        clean_title = BeautifulSoup(title, "html.parser").get_text()
                        # AI ë¶„ì„ (ìµœëŒ€ 512í† í°)
                        res = self.nlp(clean_title[:512])[0]
                        
                        score = 0
                        if res['label'] == 'positive': score = res['score']
                        elif res['label'] == 'negative': score = -res['score']
                        
                        total_score += score
                        count += 1
                        
                        # ê°€ì¥ ë¶€ì •ì ì¸ ë‰´ìŠ¤ ì¶”ì 
                        if score < worst_info["score"] and score < -0.5:
                            worst_info = {
                                "score": score,
                                "title": clean_title,
                                "link": link,
                                "source": source
                            }
                    except: continue
        
        avg_score = total_score / count if count > 0 else 0
        return avg_score, worst_info["title"], worst_info["link"], worst_info["source"]

    def get_news_sentiment(self, target_keywords):
        """ë™ê¸° ë˜í¼ í•¨ìˆ˜"""
        try:
            return asyncio.run(self.process_news_async(target_keywords))
        except Exception as e:
            print(f"ë‰´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return 0, "", "", ""

    # ------------------------------------------------------------------
    # [ë°ì´í„° ìˆ˜ì§‘] ë§¤í¬ë¡œ & ê°œë³„ ì¢…ëª©
    # ------------------------------------------------------------------
    def get_realtime_price(self, ticker):
        try:
            stock = yf.Ticker(ticker)
            return stock.fast_info.get('last_price', None)
        except: return None

    def get_market_data(self):
        """ì£¼ìš” ì§€í‘œ ì¼ê´„ ë‹¤ìš´ë¡œë“œ"""
        try:
            # ^VIX3M: 3ê°œì›” VIX (êµ¬ì¡° ë¶„ì„ìš©)
            # ^MMTW: ë‚˜ìŠ¤ë‹¥ ì¢…ëª© ì¤‘ 20ì¼ ì´í‰ì„  ìƒíšŒ ë¹„ìœ¨ (ì‹œì¥ ë„ˆë¹„) - í‹°ì»¤ í™•ì¸ í•„ìš” (ëŒ€ì•ˆ: ^NYA200R ë“±)
            # ì—¬ê¸°ì„œëŠ” ì•ˆì •ì ì¸ ë°ì´í„° í™•ë³´ë¥¼ ìœ„í•´ VIX3M ì¶”ê°€
            macro_tickers = ['NQ=F', 'QQQ', '^VIX', '^VIX3M', 'DX-Y.NYB', 'SOXX', 'HYG', '^TNX', '^IRX', 'BTC-USD']
            all_tickers = macro_tickers + list(TARGET_STOCKS.keys())
            
            data = yf.download(all_tickers, period='1mo', interval='1h', prepost=True, progress=False, ignore_tz=True)
            
            # ë©€í‹°ì¸ë±ìŠ¤ ì²˜ë¦¬
            if isinstance(data.columns, pd.MultiIndex):
                dfs = {}
                df_macro = pd.DataFrame()
                
                # Close ë°ì´í„° ì¶”ì¶œ
                if 'Close' in data.columns:
                    close_data = data['Close']
                    # í•„ìˆ˜ ë°ì´í„° ì²´í¬
                    if 'NQ=F' not in close_data.columns: return {}
                    
                    df_macro['Close'] = close_data['NQ=F']
                    df_macro['High'] = data['High']['NQ=F'] if 'High' in data.columns else close_data['NQ=F']
                    df_macro['Low'] = data['Low']['NQ=F'] if 'Low' in data.columns else close_data['NQ=F']
                    df_macro['Volume'] = data['Volume']['QQQ'] if 'Volume' in data.columns and 'QQQ' in data['Volume'].columns else 0
                    
                    # ë§¤í¬ë¡œ ì§€í‘œ ë§¤í•‘
                    ticker_map = {
                        '^VIX': 'VIX', '^VIX3M': 'VIX3M', 'DX-Y.NYB': 'DXY', 
                        'SOXX': 'SOXX', 'HYG': 'HYG', '^TNX': 'TNX', '^IRX': 'IRX', 'BTC-USD': 'BTC'
                    }
                    for t, col in ticker_map.items():
                        if t in close_data.columns:
                            df_macro[col] = close_data[t]
                    
                    df_macro = df_macro.ffill().bfill()
                    dfs['MACRO'] = df_macro
                    
                    # ê°œë³„ ì¢…ëª© ë°ì´í„° ì¶”ì¶œ
                    for ticker in TARGET_STOCKS.keys():
                        if ticker in close_data.columns:
                            df_stock = pd.DataFrame()
                            df_stock['Close'] = close_data[ticker]
                            df_stock['High'] = data['High'][ticker]
                            df_stock['Low'] = data['Low'][ticker]
                            df_stock['Volume'] = data['Volume'][ticker] if 'Volume' in data.columns else 0
                            dfs[ticker] = df_stock.dropna()
                    return dfs
            return {}
        except Exception as e:
            print(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def get_fundamental_data(self):
        try:
            start_date = datetime.now() - timedelta(days=700)
            unrate = web.DataReader('UNRATE', 'fred', start_date)
            # Sahm Rule ê³„ì‚°
            unrate['MA3'] = unrate['UNRATE'].rolling(window=3).mean()
            curr_ma3 = unrate['MA3'].iloc[-1]
            low_12m = unrate['UNRATE'].iloc[-14:-1].min()
            sahm_score = curr_ma3 - low_12m
            return {"unrate": unrate['UNRATE'].iloc[-1], "sahm_score": sahm_score, "is_recession": sahm_score >= 0.50}
        except: return None

    # ------------------------------------------------------------------
    # [ë¶„ì„ ì—”ì§„] ìœ„í—˜ ê°ì§€ ë¡œì§ (Logic Improved)
    # ------------------------------------------------------------------
    def analyze_individual(self, ticker, df_stock, df_macro):
        if df_stock.empty or len(df_stock) < 30: return None

        params = STOCK_PARAMS.get(ticker, {'crash': 30, 'rel': 15, 'tech': 15, 'sell': 60})
        
        current_price = df_stock['Close'].iloc[-1]
        prev_close = df_stock['Close'].iloc[-8] # ì•½ í•˜ë£¨ ì „ (1ì‹œê°„ë´‰ ê¸°ì¤€ 8ê°œ)
        daily_pct = (current_price - prev_close) / prev_close * 100

        # ì¼ëª©ê· í˜•í‘œ
        ichimoku = IchimokuIndicator(high=df_stock['High'], low=df_stock['Low'], window1=9, window2=26, window3=52)
        cloud_bottom = min(ichimoku.ichimoku_a().iloc[-26], ichimoku.ichimoku_b().iloc[-26])
        
        # ì´í‰ì„ 
        ma20 = SMAIndicator(close=df_stock['Close'], window=20).sma_indicator().iloc[-1]
        ma50 = SMAIndicator(close=df_stock['Close'], window=50).sma_indicator().iloc[-1]
        
        # RSI & ê±°ë˜ëŸ‰
        rsi = RSIIndicator(close=df_stock['Close'], window=14).rsi().iloc[-1]
        vol_ma = df_stock['Volume'].rolling(window=20).mean().iloc[-1]
        vol_ratio = df_stock['Volume'].iloc[-1] / vol_ma if vol_ma > 0 else 0

        # ìƒëŒ€ê°•ë„
        nq_chg = (df_macro['Close'].iloc[-1] - df_macro['Close'].iloc[-8]) / df_macro['Close'].iloc[-8] * 100
        rel_strength = daily_pct - nq_chg

        # ë‰´ìŠ¤ ë¶„ì„
        news_score, worst_n, worst_l, worst_s = self.get_news_sentiment(ticker)

        # ì ìˆ˜ ê³„ì‚°
        score = 0
        reasons = []

        if daily_pct < -3.0: score += params['crash']; reasons.append(f"ğŸ“‰ í­ë½ ({daily_pct:.1f}%)")
        if rel_strength < -1.5: score += params['rel']; reasons.append("ìƒëŒ€ì  ì•½ì„¸")
        
        tech_bad = []
        if current_price < cloud_bottom: tech_bad.append("êµ¬ë¦„ëŒ€ ì´íƒˆ")
        if ma20 < ma50 and current_price < ma20: tech_bad.append("ë°ë“œí¬ë¡œìŠ¤")
        if rsi < 30: tech_bad.append("ê³¼ë§¤ë„")
        if vol_ratio > 2.0 and daily_pct < 0: tech_bad.append("íˆ¬ë§¤ ê±°ë˜ëŸ‰")
        
        if tech_bad:
            score += params['tech']
            reasons.append(f"ê¸°ìˆ ì ({','.join(tech_bad)})")
            
        if news_score < -0.3:
            score += 20
            src = f"[{worst_s}]" if worst_s else ""
            reasons.append(f"ğŸ“° ì•…ì¬: {src} {worst_n[:15]}...")

        score = max(0, min(score, 100))
        return {"ticker": ticker, "price": current_price, "change": daily_pct, "score": score, "threshold": params['sell'], "reasons": reasons}

    def analyze_danger(self):
        dfs = self.get_market_data()
        if not dfs or 'MACRO' not in dfs: 
            print("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return
        df = dfs['MACRO']
        
        now = datetime.now() + timedelta(hours=9) # KST
        
        # ê¸°ë³¸ ë°ì´í„°
        curr_close = df['Close'].iloc[-1]
        idx_day = -24 if len(df) >= 24 else 0
        daily_chg = (curr_close - df['Close'].iloc[idx_day]) / df['Close'].iloc[idx_day] * 100
        
        # [ì‹ ê·œ] ê³ ê¸‰ ë§¤í¬ë¡œ ë¶„ì„
        vix = df['VIX'].iloc[-1]
        vix3m = df['VIX3M'].iloc[-1] if 'VIX3M' in df.columns else vix * 1.1
        # VIX ë°±ì›Œë°ì´ì…˜ (ë‹¨ê¸° ê³µí¬ > ì¤‘ê¸° ê³µí¬) = í­ë½ ì „ì¡°
        is_backwardation = vix > (vix3m * 1.02)
        vix_ratio = vix / vix3m
        
        # ë‰´ìŠ¤ ë¶„ì„
        news_score, w_title, w_link, w_src = self.get_news_sentiment(self.macro_keywords)
        
        # ìœ„í—˜ ì ìˆ˜ ê³„ì‚°
        danger_score = 0
        reasons = []
        
        # 1. ì¶”ì„¸
        if daily_chg < -1.5: danger_score += W_TREND_MACRO; reasons.append(f"ğŸ“‰ ì§€ìˆ˜ ê¸‰ë½ ({daily_chg:.2f}%)")
        
        # 2. VIX êµ¬ì¡° (í•µì‹¬ ì—…ê·¸ë ˆì´ë“œ)
        if is_backwardation:
            danger_score += 25
            reasons.append(f"ğŸš¨ VIX ë°±ì›Œë°ì´ì…˜ (ê³µí¬í™•ì‚° {vix_ratio:.2f}ë°°)")
        elif vix > 30:
            danger_score += 15
            reasons.append(f"ğŸ˜± ê³µí¬ì§€ìˆ˜ ìœ„í—˜ê¶Œ ({vix:.1f})")
            
        # 3. ë§¤í¬ë¡œ
        dxy_chg = (df['DXY'].iloc[-1] - df['DXY'].iloc[idx_day]) / df['DXY'].iloc[idx_day] * 100
        if dxy_chg > 0.3: danger_score += W_MACRO_MACRO; reasons.append("ğŸ’µ ë‹¬ëŸ¬ ê¸‰ë“±")
        
        tnx = df['TNX'].iloc[-1]
        irx = df['IRX'].iloc[-1]
        spread = tnx - irx
        if spread < -0.5: danger_score += 10; reasons.append("âš ï¸ ì¥ë‹¨ê¸° ê¸ˆë¦¬ì°¨ ì—­ì „ ì‹¬í™”")
        
        # 4. ì‹¬ë¦¬/ë‰´ìŠ¤
        if news_score < -0.25: 
            danger_score += W_VOL_MACRO
            reasons.append(f"ğŸ“° ë‰´ìŠ¤ ì‹¬ë¦¬ ì•…í™” ({news_score:.2f})")
            
        # 5. ê¸°ìˆ ì  (ì´í‰ì„ )
        ma20 = df['Close'].rolling(20).mean().iloc[-1]
        ma50 = df['Close'].rolling(50).mean().iloc[-1]
        if ma20 < ma50 and curr_close < ma20:
            danger_score += 15
            reasons.append("ğŸ“‰ ì™„ì „ ì—­ë°°ì—´ ì§„ì…")

        # ìƒ´ì˜ ë²•ì¹™
        fund = self.get_fundamental_data()
        if fund and fund['is_recession']:
            danger_score += 30
            reasons.append(f"ğŸ›‘ ê²½ê¸° ì¹¨ì²´ ì‹ í˜¸ (ìƒ´ì˜ ë²•ì¹™)")

        danger_score = max(0, min(danger_score, 100))
        
        # ìƒíƒœ ê²°ì •
        status = "ğŸŸ¢ ì•ˆì •"
        if danger_score >= TH_SELL: status = "ğŸ”´ ìœ„í—˜ (í˜„ê¸ˆí™” ê¶Œì¥)"
        elif danger_score >= TH_BUY: status = "ğŸŸ¡ ì£¼ì˜ (ê´€ë§)"
        
        # ê°œë³„ ì¢…ëª© ë¶„ì„
        stock_results = []
        for t in TARGET_STOCKS:
            if t in dfs:
                res = self.analyze_individual(t, dfs[t], df)
                if res: stock_results.append(res)
        stock_results.sort(key=lambda x: x['score'], reverse=True)

        # ë©”ì‹œì§€ ì‘ì„±
        msg = f"ğŸ”” *AI ë§ˆì¼“ ì›Œì¹˜ (Advanced)*\nğŸ“… {now.strftime('%Y-%m-%d %H:%M')} (KST)\nğŸš¦ ì‹œì¥ìƒíƒœ: {status} ({danger_score}ì )\n\n"
        
        msg += "*1ï¸âƒ£ í•µì‹¬ ìœ„í—˜ ìš”ì¸*\n"
        if reasons: msg += "\n".join(["â–ª " + r for r in reasons])
        else: msg += "â–ª íŠ¹ì´ì‚¬í•­ ì—†ìŒ (ì–‘í˜¸)"
        
        msg += f"\n\n*2ï¸âƒ£ ë§¤í¬ë¡œ ëŒ€ì‹œë³´ë“œ*\nâ€¢ ë‚˜ìŠ¤ë‹¥: {curr_close:,.0f} ({daily_chg:+.2f}%)\nâ€¢ VIXêµ¬ì¡°: {'âš ï¸ ì—­ì „' if is_backwardation else 'âœ… ì •ìƒ'} ({vix:.1f}/{vix3m:.1f})\nâ€¢ ë‹¬ëŸ¬: {df['DXY'].iloc[-1]:.2f}\nâ€¢ ê¸ˆë¦¬ì°¨: {spread:.2f}p\n"
        
        if fund: msg += f"â€¢ ì‹¤ì—…ë¥ : {fund['unrate']}%\n"
        
        if w_title:
            cl_title = re.sub(r'[\[\]\*\_]', '', w_title)[:25] + "..."
            src_tag = f"[{w_src}]" if w_src else "[News]"
            msg += f"\n*3ï¸âƒ£ ì£¼ìš” ë‰´ìŠ¤ ì‹¬ë¦¬*\nâ€¢ ì ìˆ˜: {news_score:.2f}\nâ€¢ ì´ìŠˆ: {src_tag} [{cl_title}]({w_link})\n"
            
        msg += "\n*ğŸ“Š ê´€ì‹¬ ì¢…ëª© ìœ„í—˜ë„*\n"
        for s in stock_results:
            icon = "ğŸ”´" if s['score'] >= s['threshold'] else "ğŸŸ¡" if s['score'] >= 40 else "ğŸŸ¢"
            msg += f"{icon} {s['ticker']}: {s['score']}ì  ({s['change']:+.1f}%)\n"
            if s['reasons']: msg += f"  â”” {', '.join(s['reasons'])}\n"

        self.send_telegram(msg)

if __name__ == "__main__":
    bot = DangerAlertBot()
    bot.analyze_danger()
